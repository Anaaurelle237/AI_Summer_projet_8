{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../Data/db/fraude_detection_warehouse_.db')\n",
    "\n",
    "alert = pd.read_sql_query(\"SELECT * FROM alerts\", conn)\n",
    "customers = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "devices = pd.read_sql_query(\"SELECT * FROM devices\", conn)\n",
    "transaction_history = pd.read_sql_query(\"SELECT * FROM transaction_history\", conn)\n",
    "transaction_patterns= pd.read_sql_query(\"SELECT * FROM transaction_patterns\", conn)\n",
    "transactions = pd.read_sql_query(\"SELECT * FROM transactions\", conn)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion des tables\n",
    "df1 = transactions.merge(customers, on='customer_id', how='left').drop(columns=['first_name', 'last_name', 'transaction_date'])\n",
    "df2 = df1.merge(devices, on='device_id', how='left')\n",
    "df3 = df2.merge(transaction_history, on=['customer_id', 'transaction_id'], how='left')\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = [\"registration_date\", \"date_of_birth\", \"transaction_date\", \"last_used\"]\n",
    "\n",
    "for column in date_columns:\n",
    "    df3[column] = pd.to_datetime(df3[column])\n",
    "\n",
    "df3.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df3.copy()\n",
    "data.drop(columns=[\"transaction_id\", \"customer_id\", \"device_id\", \"email\", \"phone_number\", \"address\", \"history_id\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "num_columns = list(data.select_dtypes([\"float64\"]).columns)\n",
    "for col in num_columns:\n",
    "    data[col] = scaler.fit_transform(data[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage des variables categorielles\n",
    "le = LabelEncoder()\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data[col] = le.fit_transform(data[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les composantes de date\n",
    "def extract_date_features(data, column):\n",
    "    data[f'{column}_day'] = data[column].dt.day\n",
    "    data[f'{column}_month'] = data[column].dt.month\n",
    "    data[f'{column}_year'] = data[column].dt.year\n",
    "    data[f'{column}_weekday'] = data[column].dt.weekday\n",
    "    data[f'{column}_quarter'] = data[column].dt.quarter\n",
    "    return data\n",
    "\n",
    "# Conversion des dates et extraction des caractéristiques\n",
    "date_columns = ['transaction_date','last_used', 'registration_date'] # 'date_of_birth'\n",
    "for col in date_columns:\n",
    "    data = extract_date_features(data, col)\n",
    "    \n",
    "    # Suppression de la colonne de date originale\n",
    "    data = data.drop(columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner uniquement les colonnes de date nouvellement créées\n",
    "date_columns = [col for col in data.columns if any(x in col for x in ['_day', '_month', '_year', '_weekday', '_quarter'])]\n",
    "\n",
    "# Afficher les premières lignes de ces colonnes\n",
    "print(data[date_columns].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_of_today = datetime.now()\n",
    "\n",
    "def calculate_and_assign(row):\n",
    "  years_since_birth = int((date_of_today - row['date_of_birth']).days / 360)\n",
    "  return pd.Series({'year_since_birth': years_since_birth})\n",
    "\n",
    "data[\"year_since_birth\"] = data.apply(calculate_and_assign, axis=1)\n",
    "data.drop(columns=[\"date_of_birth\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes_avec_manquantes = df3[df3.isnull().any(axis=1)]\n",
    "\n",
    "nombre_lignes_manquantes = lignes_avec_manquantes.shape[0]\n",
    "\n",
    "print(\"Nombre de lignes avec des valeurs manquantes :\", nombre_lignes_manquantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de correlation\n",
    "corr_matrix = data.corr()\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Matrice de correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection des variables les plus correlees avec is_fraud\n",
    "correlations_with_fraud = corr_matrix['is_fraud'].abs().sort_values(ascending=False)\n",
    "print(\"Top 10 variables les plus corrélées avec is_fraud:\")\n",
    "print(correlations_with_fraud.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nous utiliserons les régions comme localisation par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information mutuelle\n",
    "X = data.drop(columns=['is_fraud']) #Contient les variables explicatives (indépendantes)\n",
    "y = data['is_fraud'] #Contient la variable cible (dépendante)\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "print(\"\\nTop 10 variables selon l'information mutuelle:\")\n",
    "print(mi_scores.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection finale des variables importantes\n",
    "important_features = list(set(list(correlations_with_fraud.head(5).sort_values(ascending=False).index) + list(mi_scores.head(5).sort_values(ascending=False).index)))\n",
    "important_features = [f for f in important_features if f != 'is_fraud']\n",
    "print(\"\\nVariables importantes sélectionnées:\")\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fusionner les dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du dataset final\n",
    "X_final = data[important_features]\n",
    "y_final = data['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du modele avec Isolation Forest\n",
    "model = IsolationForest(contamination=0.5, random_state=42)\n",
    "y_pred = model.fit_predict(X_final)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluons la precision du modele\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Convertir les prédictions de l'Isolation Forest (-1 pour anomalie, 1 pour normal) \n",
    "# en format binaire (1 pour anomalie, 0 pour normal)\n",
    "#y_pred_binary = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "\n",
    "y_pred_binary = np.where(y_pred==-1, 0, y_pred)\n",
    "\n",
    "# Calculer et afficher les métriques de classification\n",
    "print(classification_report(y_final, y_pred_binary))\n",
    "\n",
    "# Calculer l'AUC-ROC\n",
    "auc_roc = roc_auc_score(y_final, y_pred_binary)\n",
    "print(f\"AUC-ROC: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_binary[:20])\n",
    "print(y_pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la matrice de confusion\n",
    "print(\"Matrice de confusion:\")\n",
    "print(confusion_matrix(y_final, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des résultats\n",
    "print(\"\\nNombre d'anomalies détectées:\", sum(y_pred == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func=chi2)\n",
    "fit = test.fit(data.drop(columns=\"is_fraud\").abs(), list(y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "features = fit.transform(data.drop(columns=\"is_fraud\"))\n",
    "print(features[0:5, :])\n",
    "feat = pd.DataFrame()\n",
    "feat[\"num_features\"] = data.drop(columns=\"is_fraud\").columns\n",
    "feat[\"score\"] = fit.scores_\n",
    "feat.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "feat = feat.reset_index().drop(columns=[\"index\"])\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_fit_transform(features):\n",
    "    X  = data[features]\n",
    "    model_1 = IsolationForest(contamination=0.5, random_state=42)\n",
    "    model_1.fit(X)\n",
    "\n",
    "    pred_1= model_1.predict(X)\n",
    "    pred_1 = np.where(pred_1==1, 0, pred_1)\n",
    "    pred_1 = np.where(pred_1==-1, 1, pred_1)\n",
    "    print(f\"{pred_1[:10]}\\n\\n\")\n",
    "\n",
    "    #evaluation\n",
    "    print(roc_auc_score(y_final, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = list(feat.head(4).num_features)\n",
    "print(len(important_features))\n",
    "print(len(feature_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_transform(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit_transform(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des customers par cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers[\"region_e\"] = le.fit_transform(customers.region)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(data.drop(columns=[\"anomalie\", \"transaction_id\", \"customer_id\", \"email\", \"transaction_date\", \"phone_number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(random_state=42)\n",
    "kmeans.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans.labels_, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier   # Importation du classificateur RandomForest\n",
    "from sklearn.metrics import classification_report, accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à la base de données SQLite\n",
    "conn = sqlite3.connect('../Data/db/fraude_detection_warehouse_.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1: Chargement les données de la table transactions\n",
    "data = pd.read_sql(\"SELECT * FROM transactions\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('is_fraud', axis=1)   # Suppression de la colonne is_fraud' pour obtenir les caractéristiques\n",
    "y = data['is_fraud'] # La cible est la colonne 'is_fraud'\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conversion de la colonne 'transaction_date' en type datetime\n",
    "X['transaction_date'] = pd.to_datetime(X['transaction_date'], errors='coerce')\n",
    "\n",
    "# Extraire jour, mois, et année de la colonne 'transaction_date'\n",
    "X['jour'] = X['transaction_date'].dt.day\n",
    "X['mois'] = X['transaction_date'].dt.month\n",
    "X['annee'] = X['transaction_date'].dt.year\n",
    "\n",
    "# Supprimer la colonne 'transaction_date'\n",
    "X = X.drop(columns=['transaction_date'])\n",
    "\n",
    "# Vérifier les changements\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes ID qui ne sont pas des features pertinentes\n",
    "X = X.drop(columns=['transaction_id', 'customer_id', 'device_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Liste des colonnes catégorielles à encoder\n",
    "cols_to_encode = ['transaction_type', 'location', 'status', ]\n",
    "\n",
    "# Encoder les colonnes en valeurs numériques\n",
    "label_encoder = LabelEncoder()\n",
    "for col in cols_to_encode:\n",
    "    X[col] = label_encoder.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Vérifier les changements\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3: Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# `test_size=0.2` signifie que 20% des données seront utilisées pour le test, 80% pour l'entraînement\n",
    "# `random_state=42` est un paramètre pour reproduire les résultats aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer et entraîner le modèle RandomForest\n",
    "modele = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele.fit(X_train, y_train)  # Entraînement du modèle sur les données d’entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modele.predict(X_test)  # Prédiction des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Calculer la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision (Accuracy) : {accuracy:.4f}\")\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\\n\", conf_matrix)\n",
    "\n",
    "# Afficher un rapport de classification détaillé (précision, rappel, F1-score)\n",
    "print(\"Rapport de classification :\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculer le score F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Score F1 : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION: notre modele a 62,63 % de predictions correctes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION DE NOTRE MODELE DE BAGGING\n",
    "\n",
    "# Définissons le modèle de base (RandomForestClassifier)\n",
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=15)\n",
    "\n",
    "# Création du BaggingClassifier avec notre modèle de base\n",
    "bagging_model = BaggingClassifier(estimator=base_model, \n",
    "                                  n_estimators=10,   # Nombre de modèles à entraîner\n",
    "                                  random_state=42,\n",
    "                                  n_jobs=-1)  # Utilisation de tous les cœurs CPU disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînons le modèle  sur nos données d'entraînement\n",
    "bagging_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  prédictions sur les données de test\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Calcul de la précision (Accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision (Accuracy) : {accuracy:.4f}\")\n",
    "\n",
    "#  matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# rapport de classification\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Rapport de classification :\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION: notre modele a 65,38 % de predictions correctes, soit 2.75% de plus que notre modele de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECHERCHE DES MEILLEURS HYPERPARAMETRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Définir la distribution des paramètres à tester\n",
    "param_dist = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'gamma': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "# Créer le modèle XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Configurer RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=50, cv=3, scoring='f1', verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Exécuter la recherche aléatoire\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "print(f\"Meilleurs paramètres trouvés : {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle XGBoost avec les meilleurs hyperparamètres trouvés\n",
    "\n",
    "best_xgb_model = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.7816396748153905,\n",
    "    gamma=0.32384506027068116,\n",
    "    learning_rate=0.010156113098594747,\n",
    "    max_depth=7,\n",
    "    n_estimators=332,\n",
    "    subsample=0.7914343774474086,\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes pour les données de test\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Précision (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"Score F1: {f1:.4f}\")\n",
    "print(\"Matrice de confusion :\\n\", confusion)\n",
    "print(\"Rapport de classification :\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la precision de notre modele de boosting est de 66,29%, soit 1% plus precis que le bagging.\n",
    "\n",
    "Cherchons a comprendre si c'est la technique qui est meilleure pour notre cas ou alors si c'est grace à l'utilisation des meilleurrs hyperparametres que nous avons de meilleurs resultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGING AVEC LES HYPERPARAMETRES TROUVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Créer le classifieur de base avec les hyperparamètres optimisés\n",
    "base_classifier = DecisionTreeClassifier(\n",
    "    max_depth=7,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Créer le modèle Bagging avec les paramètres optimisés\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=base_classifier,\n",
    "    n_estimators=332,  # équivalent à n_estimators dans XGBoost\n",
    "    max_samples=0.7914343774474086,  # équivalent à subsample dans XGBoost\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes pour les données de test\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging)\n",
    "confusion_bagging = confusion_matrix(y_test, y_pred_bagging)\n",
    "classification_rep_bagging = classification_report(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"Précision (Accuracy): {accuracy_bagging:.4f}\")\n",
    "print(f\"Score F1: {f1_bagging:.4f}\")\n",
    "print(\"Matrice de confusion :\\n\", confusion_bagging)\n",
    "print(\"Rapport de classification :\\n\", classification_rep_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERPRETATION\n",
    "PREDICTIONS CORRECTES: 66,36%\n",
    "\n",
    "Vrais négatifs (TN) : 5661 / non fraudes classées comme non fraudes Faux positifs (FP) : 5148 / non fraudes classées comme fraude Faux négatifs (FN) : 3263 / fraudes classés comme non fraudes Vrais positifs (TP) : 10 928 / fraudes classées comme fraude\n",
    "FRAUDES DETECTEES: 10 928 et FRAUDES NON DETECTEES: 3263\n",
    "\n",
    "63% de prediction correctes sur la classe de non fraude et 68% de predictions correctes sur la classe des fraudes\n",
    "(le f1 score nous montre que notre modele a mieux detecter les cas de fraudes que de non fraude)\n",
    "\n",
    "- conclusion:\n",
    "\n",
    "l'utilisaton des meilleurs hyperparametres couplé avec un arbre de decision comme modele de base a amelioré la precision de notre modele de Bagging de 1% par rapport au modele de bagging utilisant des hyperparametres aleatoires .\n",
    "En comparant les performances de nos methodes (bagging et boosting) couplés avec l'utilisation des hyperparametres trouvés, on se rend compte que les resultats en utilisant le bagging sont pratiquement egales(0.07% de difference). On conclut que utiliser un modèle d'ensemble a amélioré nos resultats. Cependant, le choix parmi les deux modèles d'ensemble a eu peu d'influence sur nos resultats mais utiliser les meilleurs hyperparametres a ete le facteur ayant le plus amelioré les resultats de nos 2 modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Entraînement du modèle (par exemple, un modèle RandomForest)\n",
    "# modèle = RandomForestClassifier(...)\n",
    "# modèle.fit(X_train, y_train)\n",
    "\n",
    "# Enregistrer le modèle entraîné\n",
    "joblib.dump(bagging_model, '../modeles/bagging_model.pkl')\n",
    "\n",
    "print(\"Le modèle a été enregistré avec succès.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyther_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
